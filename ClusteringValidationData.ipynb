{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16747d83",
   "metadata": {},
   "source": [
    "The current script is used to cluster the dependend variables of the urban air flows into five clusters. This is one out of two ways we transform the continious variables wind_speed_kmh, gust_speed_kmh, gust_angle, wind_angle into classes so that they can be used in ML models. One of the main issues with the NETATMO dataset is the size. Clustering is an efficient way to reduce processing time by reducing the amount of data. The resulting dataframe is split into testing and training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d84acb0",
   "metadata": {},
   "source": [
    "Import the required libraries. In case you have not installed these packagages, uncomment the following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff243de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc0eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f22319",
   "metadata": {},
   "source": [
    "Read the normalized data and store it in a dataframe. Make sure that your working directory is set correctly and you have run the normalization script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500d2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"norm_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e013fc",
   "metadata": {},
   "source": [
    "Remove the NA values from the dependent variables, wind_speed_kmh,wind_angle,gust_angle,gust_speed_kmh. Select the dependent variable for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c118e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any',subset=[\"wind_speed_kmh\",\"wind_angle\",\"gust_angle\",\"gust_speed_kmh\"])\n",
    "X = df[[\"wind_speed_kmh\",\"wind_angle\",\"gust_angle\",\"gust_speed_kmh\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126df5fe",
   "metadata": {},
   "source": [
    "Start the clustering by defining and fitting the model on the dependend variables. Five clusters are choosen to capture enough variability but improve processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66c046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(n_clusters=5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MiniBatchKMeans(n_clusters=5)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35752875",
   "metadata": {},
   "source": [
    "Assign a cluster to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e90603",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9184c5",
   "metadata": {},
   "source": [
    "Add the cluster IDs to the dataframe for later usage in ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b36c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_km\"] = yhat\n",
    "df = df.drop([\"wind_speed_kmh\",\"wind_angle\",\"gust_angle\",\"gust_speed_kmh\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04334fd9",
   "metadata": {},
   "source": [
    "Split the data set into testing and training data for validation and training of the ML model. 30% is used for testing, 70% for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78dd77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"temperature\",\"humidity\",\"pressure\",'rain_mm']\n",
    "X = df[feature_cols]\n",
    "y = df.class_km\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656a6ed",
   "metadata": {},
   "source": [
    "Write the testing and training data with the cluster IDs to csvs for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "749b701c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1b8e3f5d40e2>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[\"class\"] = y_train\n",
      "<ipython-input-11-1b8e3f5d40e2>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[\"class\"] = y_test\n"
     ]
    }
   ],
   "source": [
    "X_train[\"class\"] = y_train\n",
    "X_test[\"class\"] = y_test\n",
    "\n",
    "X_train.to_csv(\"train.csv\")\n",
    "X_test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff1374",
   "metadata": {},
   "source": [
    "In conclusion, the clustering was mainly challenging because of, suprise surprise, the size of the dataset. Many of the clustering algorithms tried, did not succeed because the set was too large and it took too long to create the clusters. The K batch mini means and K batch were the only algorithms out of Affinity Propagation, Agglomerative Clustering, BIRCH, DBSCAN, Mean Shift, OPTICS, Spectral Clustering and Gaussian Mixture Model that was able to run. As K batch mini means is faster for large datasets through updating the clustering based on mini batches, this algorithm was choosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecd5b76",
   "metadata": {},
   "source": [
    "A well known issue with clustering is the lack of scientific underpinning as well as the difficulty of assessing the quality of the produced cluster. The choice for the algorithm and the number of clusters was rather arbitrary. Due to time constraints I was not able to extensively examine and explore possible options. Subsequently, as the ML models performed really bad the descision was made to drop this type of modelling. As such, the data set with the clusters was not used in the analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
